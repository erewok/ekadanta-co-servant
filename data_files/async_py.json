{ "_resourceType": "BlogPost", "_pubdate": "2020-11-22T07:49:35.992456", "_contentEncoding": "ContentMarkdown", "_published": true, "_body": "Over the past few months at work, we've been writing small Python-based web services that are deployed onto Kubernetes clusters. In light of this, we've started to see some advantages to writing services with leaner profiles where we can dedicate fewer resources (CPU and memory) and still end up with a low-latency result. While some might read this and suggest instead that we should switch to other languages (such as Go), we still have a lot of people on our team comfortable with Python, and there are advantages to continuing to deploy services that the whole team is comfortable owning. To this end, we've started using a newer generation of Python web frameworks based on the ASGI spec and we've been pleased with the results.\n\nFor a previous generation of Python web frameworks (including Django, Flask, and friends), the WSGI spec, the \"Python Web Server Gateway Interface\" (see [PEP 333](https://www.python.org/dev/peps/pep-0333/)), guided how web traffic should be handled. The benefits of having a spec meant that entirely different libraries for building web servers could all reply to web requests in a generic way. This, in turn, allows something like the [gunicorn](https://gunicorn.org/) project to generically serve a request to a Django app or a Flask app, for instance, without knowing any of the internal details of those libraries.\n\nWith Python's recent adoption of `async`/`await` syntax, possibilities have opened up for building web services that exploit \"cooperative multitasking\", a form of concurrency popularized by the NodeJS ecosystem. Out of this and building on their experience with the WSGI spec, the Python community has produced a new document called [the ASGI spec](https://asgi.readthedocs.io/en/latest/index.html), which guides the flow of web requests in an `async` world.\n\nThe ASGI spec is a readable document and by following it and we can build a basic web service. This is a good exercise for exploring and understanding the spec, although it's probably obvious that achieving the feature set available in a framework like [Starlette](https://www.starlette.io/) would require significantly more effort.\n\n## Our First Attempt: Handling `scope`, `receive`, `send`\n\nThe spec starts out with a description of the basic form of an ASGI service along with an example,\n\n> In its simplest form, an application can be written as an asynchronous function, like this:\n\n```python\nasync def application(scope, receive, send):\n    event = await receive()\n    ...\n    await send({\"type\": \"websocket.send\", ...})\n```\n\nAlthough the spec covers both websockets and HTTP, we're going to restrict our efforts to HTTP here in order to start with the smallest possible featureset. We're also going to build on top of libraries like [`uvicorn`](https://pypi.org/project/uvicorn/) and [`hypercorn`](https://pypi.org/project/Hypercorn/), so that we can focus purely on implementing a service that satisfies the ASGI spec. These other libraries will translate our raw HTTP requests into something our ASGI app can respond to.\n\nWith that said, let's try this code out. We'll start with a function that takes these arguments and `send`s back some values that conform to the spec, again with a focus on HTTP requests:\n\n```python\nasync def app(scope, receive, send):\n    message = await receive()\n    if message[\"type\"] == \"http.request\":\n        body = message.get(\"body\", b\"\")\n        if body:\n            print(\"Body \", body)\n        # here's our response:\n        await send({\"type\": \"http.response.start\", \"status\": 200})\n        await send({\"type\": \"http.response.body\", \"body\": b\"OK\"})\n  \n    elif message[\"type\"] == \"http.disconnect\":\n        print(\"Disconnected! \")\n```\n\nFor our first attempt here we are ignoring the `scope` argument, a dictionary that would normally give us more detail about a request. Instead, we elect to pull a single message from the `receive` coroutine (if we have received a message of type `\"http.request\"`) and then reply with an `HTTP` response.\n\nFor HTTP [the spec dictates](https://asgi.readthedocs.io/en/latest/specs/www.html) that we should send two messages back to complete an HTTP request, the \"start\" message and the response \"body\", so that's what we'll do:\n\n```python\nawait send({\"type\": \"http.response.start\", \"status\": 200})\nawait send({\"type\": \"http.response.body\", \"body\": b\"OK\"})\n```\n\nNotice that the spec mandates that both the `send` and `receive` coroutines handle Python dictionaries and that the `scope` argument is also a dictionary. This keeps things generic. Lastly, our response `body` above must be a `bytes` object.\n\nFinally, in addition to our `app` function, we also import `uvicorn` and ask it to run our ASGI app:\n\n```python\nimport uvicorn\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"localhost\", port=8000)\n```\n\nLet's give it a try!\n\n\n```sh\n$ curl -XPOST http://localhost:8000/\nOK\n```\n\nIt works! Here are the log messages that were emitted by uvicorn on this request:\n\n```sh\n$ python demo.py\nINFO:     Started server process [87440]\nINFO:     Waiting for application startup.\nINFO:     ASGI 'lifespan' protocol appears unsupported.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\nINFO:     127.0.0.1:51053 - \"GET / HTTP/1.1\" 200 OK\n```\n\nLet's see what happens when we send in a request body:\n\n\n```sh\n$ curl -XPOST http://localhost:8000/some-random-url -d '{\"hey\": \"now\"}'\nOK\n```\n\nBecause we're printing the body received, we should see it in our logs:\n\n```sh\nINFO:     Started server process [87689]\nINFO:     Waiting for application startup.\nINFO:     ASGI 'lifespan' protocol appears unsupported.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\nBody  b'{\"hey\": \"now\"}'\nINFO:     127.0.0.1:51103 - \"POST /some-random-url HTTP/1.1\" 200 OK\n```\n\nNotice also that we're not doing _anything_ with URL-routing. Instead, we're replying to _every_ request that comes in with the same response. This means we can request any arbitrary endpoint from our app and it will always respond in the exact same way.\n\n## Switching to Hypercorn\n\nLet's try our ultra-basic ASGI app with `hypercorn` and an alternative async library [`trio`](https://pypi.org/project/trio/), just to see what happens.\n\nFirst, we'll modify our script to look like this:\n\n```python\nfrom hypercorn.config import Config\nfrom hypercorn.trio import serve\nimport trio\n\nif __name__ == \"__main__\":\n    config = Config()\n    config.bind = [\"localhost:8000\"]\n    trio.run(partial(serve, app, config))\n```\n\n\nAfter that, we'll fire it up and see what happens when we issue a request:\n\n```sh\n$ curl http://localhost:8000\ncurl: (7) Failed to connect to localhost port 8000: Connection refused\n```\n\nHmm. That seems problematic. What do our application logs report...\n\nUnfortunately, there is _no_ output in our logs until we hit CTRL+C to terminate the app, at which point we see the following:\n```sh\n$ python demo.py\n\n^CTraceback (most recent call last):\n  File \"demo.py\", line 195, in <module>\n    trio.run(partial(serve, app, config))\n  File \".lib/python3.8/site-packages/trio/_core/_run.py\", line 1896, in run\n    raise runner.main_task_outcome.error\n  File \".lib/python3.8/site-packages/hypercorn/trio/__init__.py\", line 42, in serve\n    await worker_serve(app, config, shutdown_trigger=shutdown_trigger, task_status=task_status)\n  File \".lib/python3.8/site-packages/hypercorn/trio/run.py\", line 40, in worker_serve\n    await lifespan.wait_for_startup()\n  File \".lib/python3.8/site-packages/hypercorn/trio/lifespan.py\", line 49, in wait_for_startup\n    await self.startup.wait()\n  File \".lib/python3.8/site-packages/trio/_sync.py\", line 66, in wait\n    await self._lot.park()\n  File \".lib/python3.8/site-packages/trio/_core/_parking_lot.py\", line 136, in park\n    await _core.wait_task_rescheduled(abort_fn)\n  File \".lib/python3.8/site-packages/trio/_core/_traps.py\", line 166, in wait_task_rescheduled\n    return (await _async_yield(WaitTaskRescheduled(abort_func))).unwrap()\n  File \".lib/python3.8/site-packages/outcome/_sync.py\", line 111, in unwrap\n    raise captured_error\n  File \".lib/python3.8/site-packages/trio/_core/_run.py\", line 1107, in raise_cancel\n    raise KeyboardInterrupt\nKeyboardInterrupt\n```\n\nIt's maybe not so obvious what's going on here, but if we switch our application instance to reply to _any_ invocation with an HTTP response, the problem will likely become clearer (in addition to including a longer traceback).\n\nFirst, we'll _temporarily_ replace our app function with the following code:\n\n```python\nasync def app(scope, receive, send):\n    await send({\"type\": \"http.response.start\", \"status\": 200})\n    await send({\"type\": \"http.response.body\", \"body\": b\"OK\"})\n```\n\nThis will treat _any_ invocation as an HTTP request and send back an HTTP response.\n\nAfter that, when we run it and we send a `SIGTERM`, we'll see the following:\n```sh\nASGI Framework Lifespan error, continuing without Lifespan support\nTraceback (most recent call last):\n  File \"./lib/python3.8/site-packages/hypercorn/trio/lifespan.py\", line 29, in handle_lifespan\n    await invoke_asgi(self.app, scope, self.asgi_receive, self.asgi_send)\n  File \"./lib/python3.8/site-packages/hypercorn/utils.py\", line 219, in invoke_asgi\n    await app(scope, receive, send)\n  File \"demo.py\", line 156, in app_v1\n    await send({\"type\": \"http.response.start\", \"status\": 200})\n  File \"./lib/python3.8/site-packages/hypercorn/trio/lifespan.py\", line 77, in asgi_send\n    raise UnexpectedMessage(message[\"type\"])\nhypercorn.trio.lifespan.UnexpectedMessage: http.response.start\nTraceback (most recent call last):\n  File \"./lib/python3.8/site-packages/trio/_timeouts.py\", line 105, in fail_at\n    yield scope\n  File \"./lib/python3.8/site-packages/hypercorn/trio/lifespan.py\", line 49, in wait_for_startup\n    await self.startup.wait()\n  File \"./lib/python3.8/site-packages/trio/_sync.py\", line 66, in wait\n    await self._lot.park()\n  File \"./lib/python3.8/site-packages/trio/_core/_parking_lot.py\", line 136, in park\n    await _core.wait_task_rescheduled(abort_fn)\n  File \"./lib/python3.8/site-packages/trio/_core/_traps.py\", line 166, in wait_task_rescheduled\n    return (await _async_yield(WaitTaskRescheduled(abort_func))).unwrap()\n  File \"./lib/python3.8/site-packages/outcome/_sync.py\", line 111, in unwrap\n    raise captured_error\n  File \"./lib/python3.8/site-packages/trio/_core/_run.py\", line 1096, in raise_cancel\n    raise Cancelled._create()\ntrio.Cancelled: Cancelled\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"./lib/python3.8/site-packages/hypercorn/trio/lifespan.py\", line 49, in wait_for_startup\n    await self.startup.wait()\n  File \"./lib/python3.8/contextlib.py\", line 131, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"./lib/python3.8/site-packages/trio/_timeouts.py\", line 107, in fail_at\n    raise TooSlowError\ntrio.TooSlowError\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"demo.py\", line 177, in <module>\n    trio.run(partial(serve, app, config))\n  File \"./lib/python3.8/site-packages/trio/_core/_run.py\", line 1896, in run\n    raise runner.main_task_outcome.error\n  File \"./lib/python3.8/site-packages/hypercorn/trio/__init__.py\", line 42, in serve\n    await worker_serve(app, config, shutdown_trigger=shutdown_trigger, task_status=task_status)\n  File \"./lib/python3.8/site-packages/hypercorn/trio/run.py\", line 40, in worker_serve\n    await lifespan.wait_for_startup()\n  File \"./lib/python3.8/site-packages/hypercorn/trio/lifespan.py\", line 51, in wait_for_startup\n    raise LifespanTimeout(\"startup\") from error\nhypercorn.utils.LifespanTimeout: Timeout whilst awaiting startup. Your application may not support the ASGI Lifespan protocol correctly, alternatively the startup_timeout configuration is incorrect.\n```\n\nThis last error should make things a bit clearer: our application doesn't handle _lifespan_ events. Indeed, looking back at our logs while running with `uvicorn`, we'll see an innocuous-looking message that corroborates this:\n\n\n```sh\nINFO:     Waiting for application startup.\nINFO:     ASGI 'lifespan' protocol appears unsupported.\nINFO:     Application startup complete.\n```\n\nIt turns out that `hypercorn` is less forgiving about a failure to handle the `lifespan` protocol than `uvicorn`! So what _is_ the `lifespan` protocol?\n\n## Lifespan Events\n\nFrom the hints given by this massive traceback, we can see that our failure to run our basic service with `hypercorn` has to do with a failure to adequately handle `lifespan` events. Returning to the ASGI spec's [section on lifespan evnts](https://asgi.readthedocs.io/en/latest/specs/lifespan.html), we find the following text:\n\n\n> The lifespan messages allow for an application to initialise and shutdown in the context of a running event loop. An example of this would be creating a connection pool and subsequently closing the connection pool to release the connections.\n>\n> A possible implementation of this protocol is given below:\n\n```python\nasync def app(scope, receive, send):\n    if scope['type'] == 'lifespan':\n        while True:\n            message = await receive()\n            if message['type'] == 'lifespan.startup':\n                ... # Do some startup here!\n                await send({'type': 'lifespan.startup.complete'})\n            elif message['type'] == 'lifespan.shutdown':\n                ... # Do some shutdown here!\n                await send({'type': 'lifespan.shutdown.complete'})\n                return\n    else:\n        pass # Handle other types\n```\n\nWith code snippets like these provided by the spec, we can quickly get started handling these events. Let's use the example given above and join it to our existing application.\n\nTo simplify it somewhat, we'll create a new, primary application function and then send any actual requests that are not `lifespan` events into our previous `app` function:\n\n```python\nasync def app(scope, receive, send):\n    message = await receive()\n    if message[\"type\"] == \"http.request\":\n        body = message.get(\"body\", b\"\")\n        if body:\n            print(\"Body \", body)\n        # here's our response:\n        await send({\"type\": \"http.response.start\", \"status\": 200})\n        await send({\"type\": \"http.response.body\", \"body\": b\"OK\"})\n  \n    elif message[\"type\"] == \"http.disconnect\":\n        print(\"Disconnected! \")\n\n\nasync def app_lifespan(scope, receive, send):\n    if scope[\"type\"] == \"lifespan\":\n        while True:\n            message = await receive()\n            if message[\"type\"] == \"lifespan.startup\":\n                ...  # Do some startup here!\n                await send({\"type\": \"lifespan.startup.complete\"})\n            elif message[\"type\"] == \"lifespan.shutdown\":\n                ...  # Do some shutdown here!\n                await send({\"type\": \"lifespan.shutdown.complete\"})\n                return\n    if scope[\"type\"] == \"http\":\n        return await app(scope, receive, send)\n```\n\nLet's try this latest version with our `trio`/`hypercorn` version again:\n\n\n```sh\n$ python demo.py\nRunning on 127.0.0.1:8000 over http (CTRL + C to quit)\n```\n\nNow this looks a lot more promising: we no longer have error messages about unhandled \"lifespan\" events. Let's issue a request and see what happens:\n\n```sh\n$ curl -XPOST http://localhost:8000/some-random-url -d '{\"hey\": \"now\"}'\nOK\n```\n\nSo it looks to be working again. After checking the logs for our service, we should see this request body appear, just as before while running with `uvicorn`:\n\n```sh\nBody  b'{\"hey\": \"now\"}'\n```\n\n## Using Scope\n\nNow, the application we're writing would not be a very interesting web server except perhaps as some kind of odd health check. However, to perform more interesting work, we'll need to start utlizing the `scope` argument passed into our app. In an HTTP request, `scope` is where all of the useful auxiliary information about the request (aside from the request body) would be present.\n\nLet's start by printing out the `scope` and seeing what elements we can use. First, we'll modify our app to print the `scope` on each invocation:\n\n\n```python\nasync def app_lifespan(scope, receive, send):\n    print(scope)\n    if scope[\"type\"] == \"lifespan\":\n        while True:\n          ...\n```\n\nWith this, we can make a few requests and see what our `scope` looks like.\n\nAfter restarting our server and rerunning the previous requests from above, we should see something like the following:\n\n```sh\n{'type': 'lifespan', 'asgi': {'spec_version': '2.0', 'version': '3.0'}}\nRunning on 127.0.0.1:8000 over http (CTRL + C to quit)\n{'type': 'http', 'http_version': '1.1', 'asgi': {'spec_version': '2.1', 'version': '3.0'}, 'method': 'POST', 'scheme': 'http', 'path': '/some-random-url', 'raw_path': b'/some-random-url', 'query_string': b'', 'root_path': '', 'headers': [(b'host', b'localhost:8000'), (b'user-agent', b'curl/7.64.1'), (b'accept', b'*/*'), (b'content-length', b'14'), (b'content-type', b'application/x-www-form-urlencoded')], 'client': ('127.0.0.1', 50027), 'server': ('127.0.0.1', 8000)}\n```\n\nThere are three lines of text here, two lines from printing the `scope` sandwiched around a message from `hypercorn` which tells us that our app is running.\n\nThe first printed `scope` is of type `lifespan`, while the second is of type `http`. This makes sense from what we've learned so far.\n\nFurther, from the `scope` dictionary present on our HTTP request,  we can see various keys and values that would also be useful for constructing a more fully featured web framework:\n\n```python\n'method': 'POST',\n'scheme': 'http',\n'path': '/some-random-url',\n'raw_path': b'/some-random-url',\n'query_string': b'',\n'root_path': '',\n'headers': [list-of-tuples-of-bytes]\n```\n\n## Request Routing\n\nLet's assume we'd like to modify our simple ASGI app to handle some simple request routing. Here, we'll offer only two routes, and these will represent different types of `Content-Type` responses. We'll also create a way to reply to requests for unknown paths (404s).\n\nBecause we have only two types of requests, we'll use a dictionary to map the request path to its appropriate handler and we'll default to our 404 handler if we can't match the path. (And it probably goes without saying that request routing can get more complicated than this, but it should suffice for demonstration purposes.)\n\nFirst, we'll create a handler for plaintext and one for JSON, like this:\n\n```python\nasync def plaintext_handler(scope, receive, send):\n    await send({\"type\": \"http.response.start\", \"status\": 200})\n    await send({\"type\": \"http.response.body\", \"body\": b\"OK\"})\n\n\nasync def json_handler(scope, receive, send):\n    if (b\"content-type\", b\"application/json\") not in scope[\"headers\"]:\n        await unknown_handler(scope, receive, send)\n        return None\n\n    message = await receive()\n    body = message.get(\"body\", b\"\")\n    data = json.loads(body)\n    payload = {\"received\": data, \"emperor\": \"of ice cream\"}\n    await send(\n        {\"type\": \"http.response.start\", \"status\": 200, \"headers\": [(b\"content-type\", b\"application/json\")]}\n    )\n    await send(\n        {\"type\": \"http.response.body\", \"body\": json.dumps(payload).encode(\"utf-8\")}\n    )\n```\n\nWe'll also create a fallback to handle requests for unknown paths and you may notice that we've already included a call to this handler above for when JSON-matched requests comes in without the proper `Content-Type` header:\n\n```python\nasync def unknown_handler(scope, receive, send):\n    await send(\n        {\n            \"type\": \"http.response.start\",\n            \"status\": 404,\n            \"headers\": [(b\"Content-Type\", b\"text/html; charset=UTF-8\")],\n        }\n    )\n    await send(\n        {\n            \"type\": \"http.response.body\",\n            \"body\": b\"<html><body><h1>404 Not Found!</h1></body></html>\",\n        }\n    )\n```\n\nIn this case, we've elected to make a fancy HTML page for our 404s (granted, it's not _that_ fancy).\n\nLastly, here's the dictionary we'll use to match routes to handlers when a new request comes in, defaulting to the `unknown_handler` when a requested path doesn't match a known endpoint:\n\n```python\nROUTE_HANDLERS = {\"/json\": json_handler, \"/plaintext\": plaintext_handler}\n\n\nasync def app(scope, receive, send):\n    handler = ROUTE_HANDLERS.get(scope[\"path\"], unknown_handler)\n    await handler(scope, receive, send)\n```\nNote: Here, I have also removed the first `message = await receive()` call as well as the check for `message[\"type\"]` because I want my handlers to be able to pull messages out of the `receive` coroutine.\n\nFinally, after making these changes and running the new version of our app in another terminal, I'll make some requests and see what we get in response:\n\n```sh\n$ curl -XPOST http://localhost:8000/plaintext\nOK\n$ curl -XPOST -H \"Content-Type: application/json\" http://localhost:8000/json -d '{\"Hey\": \"JSON\"}'\n{\"received\": {\"Hey\": \"JSON\"}, \"emperor\": \"of ice cream\"}\n$ curl -XPOST http://localhost:8000/UNKNOWN\n<html><body><h1>404 Not Found!</h1></body></html>\n```\n\nNotice that I am submitting the header `\"Content-Type: application/json\"`, but _matching_ the header `(b\"content-type\", b\"application/json\")`: this is because headers are automatically lower-cased owing to the fact that HTTP headers are meant to be case-insensitive.\n\nAs we can see, it seems to be working. We should also see that we get the same `unknown_handler` response if we leave off the `Content-Type` header when requesting our JSON endpoint:\n\n```sh\n$ curl -XPOST http://localhost:8000/json -d '{\"Hey\": \"JSON\"}'\n<html><body><h1>404 Not Found!</h1></body></html>\n```\n\n## Building Out: Background and Middleware\n\nAs I've stated at various points above, an extremely simple application like the above, while certainly useful for demonstrating how to write an application that meets the ASGI spec, is still pretty far from a full-fledged web server. There are hints, though, as to how to progress further: we could use the `scope` argument to pull out query paramaters, headers, and the requested path, and we could also use the `receive` coroutine to retrieve and process the request body (even in cases of streaming).\n\nThere are also other interesting aspects of the ASGI spec that we haven't covered here, including [\"middleware\"](https://asgi.readthedocs.io/en/latest/specs/main.html#middleware) and [\"Extra Coroutines\"](https://asgi.readthedocs.io/en/latest/specs/main.html#extra-coroutines). The latter, in fact, is one of the most appealing things to my team because for our Python applications we have typically had to launch Celery processes when we have computations that don't want clients to have to wait for, such as for routine data management or simple tasks such as sending email. This concept of \"Extra Coroutines\" has been able to free us from shipping as many Celery deployments, but we do still often find ourselves reaching for it when we have CPU-intensive or lengthier processes.\n\nOn the whole [the ASGI spec](https://asgi.readthedocs.io/en/latest/specs/main.html#) is a readable and informative document, and I encourage reading through it if only to understand in more detail what the async web frameworks in the Python world are all about.", "_title": "Async Python", "_lede": "Some lede", "_tags": [], "_featuredImage": null, "_pid": null }